---
phase: 02-statistical-analysis-domain-insights
plan: 04
type: execute
wave: 3
depends_on: [02-01, 02-02]
files_modified:
  - src/clustering.py
  - scripts/11_provider_clustering.py
  - data/processed/provider_clusters.parquet
  - reports/figures/provider_cluster_analysis.png
  - reports/figures/silhouette_scores.png
  - reports/figures/elbow_plot.png
  - reports/provider_clustering_2026-01-18.md
autonomous: true

must_haves:
  truths:
    - "Providers clustered by performance characteristics (intelligence, price, speed)"
    - "Optimal cluster count determined by silhouette score and elbow method"
    - "Cluster profiles reveal market segments and competitive positioning"
    - "Regional comparisons identify differences between US, China, and European providers"
  artifacts:
    - path: "src/clustering.py"
      provides: "Provider clustering utilities with validation"
      exports: ["aggregate_by_provider", "find_optimal_clusters", "cluster_providers", "validate_clustering"]
      min_lines: 200
    - path: "scripts/11_provider_clustering.py"
      provides: "Provider clustering pipeline"
      min_lines: 100
    - path: "data/processed/provider_clusters.parquet"
      provides: "Provider-level dataset with cluster assignments"
      contains: "cluster column"
    - path: "reports/figures/provider_cluster_analysis.png"
      provides: "Cluster visualization with provider labels"
    - path: "reports/figures/silhouette_scores.png"
      provides: "Silhouette score analysis for optimal K"
    - path: "reports/figures/elbow_plot.png"
      provides: "Elbow method plot for cluster validation"
    - path: "reports/provider_clustering_2026-01-18.md"
      provides: "Narrative report of clustering findings with regional comparisons"
  key_links:
    - from: "scripts/11_provider_clustering.py"
      to: "data/processed/ai_models_deduped.parquet"
      via: "Input deduplicated dataset"
      pattern: "ai_models_deduped"
    - from: "src/clustering.py"
      to: "sklearn.cluster"
      via: "KMeans clustering algorithm"
      pattern: "from sklearn\\.cluster import KMeans"
    - from: "src/clustering.py"
      to: "sklearn.preprocessing"
      via: "StandardScaler for feature normalization"
      pattern: "from sklearn\\.preprocessing import StandardScaler"
    - from: "data/processed/provider_clusters.parquet"
      to: "scripts/10_statistical_tests.py"
      via: "Provider clusters for group comparisons"
      pattern: "cluster"
---

<objective>
Segment providers by performance characteristics using KMeans clustering to identify market segments, competitive groups, and strategic positioning across US, China, and European providers.

Purpose: Discover natural groupings of providers based on their models' intelligence, pricing, and speed. Cluster analysis reveals market structure (e.g., premium providers, budget providers, performance-focused providers) and enables provider comparisons across regions.

Output: Provider clusters with validation (silhouette scores, elbow method), cluster visualizations, regional comparison analysis, and narrative report identifying market segments (STAT-04, STAT-06).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-statistical-analysis-domain-insights/02-RESEARCH.md

@data/processed/ai_models_deduped.parquet
@src/analyze.py
@.planning/phases/02-statistical-analysis-domain-insights/02-01-SUMMARY.md
@.planning/phases/02-statistical-analysis-domain-insights/02-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement clustering utilities</name>
  <files>src/clustering.py</files>
  <action>
Create src/clustering.py with script-as-module pattern:

**Functions to implement:**

1. `aggregate_by_provider(df: pl.DataFrame, features: list[str]) -> pl.DataFrame`
   - Group by Creator column
   - Aggregate features: mean intelligence, mean price, mean speed
   - Add count: number of models per provider
   - Return provider-level DataFrame
   - Handle nulls in intelligence_index (filter to valid scores)

2. `find_optimal_clusters(X_scaled: np.ndarray, max_k: int = 10) -> dict`
   - Use sklearn.cluster.KMeans with random_state=42, n_init=10
   - Test k from 2 to max_k
   - For each k:
     - Fit KMeans: kmeans.fit(X_scaled)
     - Compute silhouette_score: sklearn.metrics.silhouette_score(X_scaled, labels)
     - Store inertia: kmeans.inertia_
   - Find optimal_k: argmax(silhouette_scores)
   - Return dict: {optimal_k, silhouette_scores, inertias, all_labels}

3. `cluster_providers(df_provider: pl.DataFrame, features: list[str], n_clusters: int = None) -> pl.DataFrame`
   - Extract features: X = df_provider.select(features).to_numpy()
   - Scale features: StandardScaler().fit_transform(X)
   - Find optimal clusters if n_clusters is None
   - Fit final KMeans with optimal_k
   - Add cluster column to DataFrame
   - Return DataFrame with cluster assignments
   - Also return scaler and model for inverse transformation if needed

4. `validate_clustering(X_scaled: np.ndarray, labels: np.ndarray) -> dict`
   - Compute silhouette_score (overall)
   - Compute silhouette scores per sample
   - Calculate cluster centroids (mean in scaled space)
   - Return validation metrics

5. `assign_region(creator: str) -> str`
   - Map Creator names to regions (US, China, Europe, Other)
   - Use known mappings: OpenAI=US, Anthropic=US, Google=US, Meta=US, Microsoft=US
   - DeepSeek=China, Alibaba=China, Tencent=China, Baidu=China
   - Mistral=Europe, Aleph Alpha=Europe
   - Return "Other" for unknown providers
   - Handle case-insensitive matching

6. `compare_regions(df: pl.DataFrame, metric: str) -> dict`
   - Group by region column
   - Compute mean, median, std for specified metric
   - Return regional comparison statistics
   - Use for STAT-04 requirement

**Dependencies:**
- Import sklearn.cluster.KMeans, sklearn.preprocessing.StandardScaler
- Import sklearn.metrics.silhouette_score
- Import numpy as np, polars as pl
- Use pattern from src/analyze.py for statistical utilities

**Key decisions (from RESEARCH.md Pattern 6):**
- Scale features before clustering (StandardScaler)
- Use silhouette score for quantitative validation (not just elbow method)
- Use KMeans on provider-level aggregates (not model-level)
- Manual region mapping for major providers
  </action>
  <verify>
```bash
# Test clustering functions
python3 -c "
import sys
sys.path.insert(0, '.')
from src.clustering import aggregate_by_provider, find_optimal_clusters, assign_region
import polars as pl
import numpy as np

# Test provider aggregation
df = pl.read_parquet('data/processed/ai_models_deduped.parquet')
df_valid = df.filter(pl.col('Intelligence Index').is_not_null())
provider_df = aggregate_by_provider(df_valid, ['intelligence_index', 'price_usd'])
print(f'Providers: {len(provider_df)}')
print(provider_df.head())

# Test region assignment
test_creators = ['OpenAI', 'DeepSeek', 'Mistral', 'Unknown Provider']
for creator in test_creators:
    region = assign_region(creator)
    print(f'{creator} -> {region}')

# Test optimal clusters (small sample)
from sklearn.preprocessing import StandardScaler
X = provider_df.select(['avg_intelligence', 'avg_price']).to_numpy()
X_scaled = StandardScaler().fit_transform(X)
results = find_optimal_clusters(X_scaled, max_k=5)
print(f'Optimal K: {results[\"optimal_k\"]}')
"
```
  </verify>
  <done>
- aggregate_by_provider() creates provider-level aggregates
- find_optimal_clusters() returns optimal K and validation metrics
- assign_region() maps creators to regions correctly
- Features scaled properly before clustering
- Functions handle null values appropriately
  </done>
</task>

<task type="auto">
  <name>Task 2: Execute provider clustering pipeline</name>
  <files>scripts/11_provider_clustering.py</files>
  <action>
Create scripts/11_provider_clustering.py as executable script:

**Script structure:**
```python
#!/usr/bin/env python3
"""
Provider Clustering Pipeline - Phase 2 Plan 04

Segments providers by performance characteristics using KMeans clustering.
Identifies market segments and competitive positioning with regional comparisons.

Usage:
    PYTHONPATH=. python3 scripts/11_provider_clustering.py
"""

import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from src.clustering import (
    aggregate_by_provider,
    find_optimal_clusters,
    cluster_providers,
    validate_clustering,
    assign_region,
    compare_regions
)
from pathlib import Path
from datetime import datetime

def main():
    # Load deduplicated dataset
    input_path = "data/processed/ai_models_deduped.parquet"
    output_path = "data/processed/provider_clusters.parquet"
    report_path = "reports/provider_clustering_2026-01-18.md"

    print(f"Loading: {input_path}")
    df = pl.read_parquet(input_path)
    print(f"Loaded {df.height} models")

    # Filter to models with valid intelligence scores
    df_valid = df.filter(pl.col("Intelligence Index").is_not_null())
    print(f"Models with valid intelligence: {df_valid.height}")

    # Aggregate by provider
    print("\n=== AGGREGATING BY PROVIDER ===")
    provider_df = aggregate_by_provider(
        df_valid,
        ["Intelligence Index", "price_usd", "Speed(median token/s)"]
    )
    print(f"Unique providers: {len(provider_df)}")

    # Assign regions
    provider_df = provider_df.with_columns(
        pl.col("Creator").map_elements(assign_region, return_dtype=pl.Utf8).alias("region")
    )
    print(f"Regions: {provider_df['region'].unique().to_list()}")

    # Cluster providers
    print("\n=== CLUSTERING PROVIDERS ===")
    features = ["avg_intelligence", "avg_price", "avg_speed"]
    clustered_df = cluster_providers(provider_df, features)
    print(f"Optimal clusters: {clustered_df['cluster'].n_unique()}")

    # Validate clustering
    print("\n=== VALIDATING CLUSTERS ===")
    from sklearn.preprocessing import StandardScaler
    X = provider_df.select(features).to_numpy()
    X_scaled = StandardScaler().fit_transform(X)
    validation = validate_clustering(X_scaled, clustered_df["cluster"].to_numpy())
    print(f"Silhouette score: {validation['silhouette_score']:.3f}")

    # Save results
    print(f"\nSaving: {output_path}")
    clustered_df.write_parquet(output_path)

    # Generate cluster visualizations
    print("\n=== GENERATING VISUALIZATIONS ===")
    create_cluster_visualizations(clustered_df, features, validation)

    # Generate regional comparison
    print("\n=== REGIONAL COMPARISON ===")
    regional_comparison = compare_regions_by_metric(df_valid)

    # Generate clustering report
    generate_clustering_report(
        clustered_df,
        validation,
        regional_comparison,
        report_path
    )
    print(f"Report: {report_path}")

    print("\nâœ“ Provider clustering complete")

def create_cluster_visualizations(df, features, validation):
    """Create cluster analysis visualizations."""
    # 1. Silhouette scores plot
    plt.figure(figsize=(10, 6))
    k_range = range(2, len(validation['silhouette_scores']) + 2)
    plt.plot(k_range, validation['silhouette_scores'], 'bo-')
    plt.axvline(x=validation['optimal_k'], color='r', linestyle='--', label=f'Optimal K={validation["optimal_k"]}')
    plt.xlabel('Number of Clusters (K)')
    plt.ylabel('Silhouette Score')
    plt.title('Silhouette Score Analysis for Optimal K')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig('reports/figures/silhouette_scores.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 2. Elbow plot
    plt.figure(figsize=(10, 6))
    plt.plot(k_range, validation['inertias'], 'bo-')
    plt.xlabel('Number of Clusters (K)')
    plt.ylabel('Inertia (Within-Cluster Sum of Squares)')
    plt.title('Elbow Method for Cluster Validation')
    plt.grid(True, alpha=0.3)
    plt.savefig('reports/figures/elbow_plot.png', dpi=300, bbox_inches='tight')
    plt.close()

    # 3. Cluster scatter plot (2D projection)
    # ... implementation ...

def compare_regions_by_metric(df: pl.DataFrame) -> dict:
    """Compare providers by region across key metrics."""
    # Assign regions to model-level data
    df_with_region = df.with_columns(
        pl.col("Creator").map_elements(assign_region, return_dtype=pl.Utf8).alias("region")
    )

    # Compare by intelligence, price, speed
    metrics = ["Intelligence Index", "price_usd", "Speed(median token/s)"]
    regional_stats = {}

    for metric in metrics:
        try:
            # Cast to Float64 for numeric operations
            regional_stats[metric] = df_with_region.group_by("region").agg([
                pl.col(metric).cast(pl.Float64).mean().alias("mean"),
                pl.col(metric).cast(pl.Float64).median().alias("median"),
                pl.col(metric).cast(pl.Float64).std().alias("std"),
                pl.len().alias("count")
            ]).sort("region")
        except Exception as e:
            print(f"Warning: Could not compute regional stats for {metric}: {e}")

    return regional_stats

def generate_clustering_report(df, validation, regional_comparison, output_path):
    """Generate narrative report of clustering findings."""
    # Implement report generation with:
    # - Cluster summary (number of providers per cluster)
    # - Cluster profiles (what defines each segment?)
    # - Market segments identified
    # - Regional comparisons (US vs China vs Europe)
    # - Silhouette score interpretation
    # - Provider list by cluster
    # Follow pattern from scripts/05_quality_report.py

    # ... implementation ...

if __name__ == "__main__":
    main()
```

**Implement generate_clustering_report():**
- Section 1: Cluster Validation (silhouette score, optimal K)
- Section 2: Cluster Profiles (characteristics of each segment)
- Section 3: Market Segments (premium, budget, performance-focused)
- Section 4: Regional Comparison (US vs China vs Europe per STAT-04)
- Section 5: Provider Listing by Cluster
- Section 6: Strategic Insights

**Implement cluster scatter plot:**
- 2D visualization using first two features (or PCA)
- Color by cluster
- Label key providers
- Add centroids

**Follow pattern from:** scripts/08_correlation_analysis.py (pipeline), scripts/05_quality_report.py (report), src/analyze.py (visualization)
  </action>
  <verify>
```bash
# Execute script
PYTHONPATH=. python3 scripts/11_provider_clustering.py

# Verify output files
ls -lh data/processed/provider_clusters.parquet
ls -lh reports/figures/silhouette_scores.png
ls -lh reports/figures/elbow_plot.png
ls -lh reports/figures/provider_cluster_analysis.png
ls -lh reports/provider_clustering_2026-01-18.md

# Verify clustering results
python3 -c "
import polars as pl
df = pl.read_parquet('data/processed/provider_clusters.parquet')
print(f'Providers: {df.height}')
print(f'Clusters: {df[\"cluster\"].n_unique()}')
print(f'Clusters: {sorted(df[\"cluster\"].unique().to_list())}')
print(f'Regions: {df[\"region\"].unique().to_list()}')
print('Providers per cluster:')
print(df.group_by('cluster').agg(pl.len().alias('count')).sort('cluster'))
"
```
  </verify>
  <done>
- Script executes without errors
- Provider aggregation completed (N providers from 188 models)
- Optimal cluster count determined by silhouette score
- Clusters assigned to providers
- Validation metrics computed (silhouette score, inertia)
- Regional comparison completed (US vs China vs Europe)
- Visualizations generated (silhouette, elbow, cluster plot)
- Report generated with market segments and regional insights
  </done>
</task>

</tasks>

<verification>
## Overall Verification Steps

1. **Aggregation Verification:**
   - Provider-level aggregates computed correctly
   - Features: avg_intelligence, avg_price, avg_speed
   - Count of models per provider included
   - Null intelligence scores filtered out

2. **Clustering Verification:**
   - Features scaled (StandardScaler applied)
   - Optimal K determined by silhouette score
   - KMeans clustering with appropriate parameters
   - Cluster assignments added to DataFrame

3. **Validation Verification:**
   - Silhouette score computed (higher is better, max 1.0)
   - Elbow method plot shows inertia vs K
   - Both validation methods agree on optimal K

4. **Regional Comparison Verification:**
   - Region assignment mapping correct for major providers
   - Regional statistics computed (mean, median, std)
   - US vs China vs Europe comparison completed
   - STAT-04 requirement satisfied

5. **Visualization Verification:**
   - Silhouette score plot shows optimal K
   - Elbow plot shows inertia curve
   - Cluster visualization shows provider segments
   - High resolution (300 DPI)

6. **Documentation Verification:**
   - Cluster profiles documented
   - Market segments identified
   - Regional comparison provided
   - Provider listings by cluster
   - Strategic insights included

7. **Reproducibility Verification:**
   - Random seed set (random_state=42)
   - All code documented
   - Functions importable by notebook
</verification>

<success_criteria>
- [ ] Provider aggregation completed (N providers)
- [ ] Optimal cluster count determined by silhouette score
- [ ] Clusters assigned to all providers
- [ ] Validation metrics computed (silhouette, inertia)
- [ ] Regional comparison completed (US vs China vs Europe)
- [ ] Three visualizations generated (silhouette, elbow, cluster plot)
- [ ] Narrative report with market segments and regional insights
- [ ] Cluster profiles documented
- [ ] Provider listings by cluster
- [ ] Functions importable by notebook
- [ ] Dependencies on Plans 02-01 and 02-02 satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/02-statistical-analysis-domain-insights/02-04-SUMMARY.md` with:
- Cluster summary (optimal K, number of providers per cluster)
- Market segments identified (premium, budget, performance-focused)
- Regional comparison findings (US vs China vs Europe)
- Validation metrics (silhouette score)
- Visualizations generated
- Dependencies on Plans 02-01 and 02-02
</output>
