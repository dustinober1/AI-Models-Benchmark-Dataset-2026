---
phase: 01-data-pipeline
plan: 02
type: execute
wave: 2
depends_on: [01-01]
files_modified:
  - data/interim/01_loaded.parquet
  - src/load.py
  - src/validate.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "CSV data is loaded using Polars LazyFrame with explicit schema definition"
    - "Data structure is documented with column names, types, ranges, and sample values"
    - "Schema validation catches type mismatches and impossible values"
    - "Invalid records are quarantined to separate file for review"
  artifacts:
    - path: "data/interim/01_loaded.parquet"
      provides: "Loaded dataset with validated schema"
      format: "parquet"
    - path: "src/load.py"
      provides: "Data loading utilities with schema validation"
      exports: ["load_data", "document_structure"]
    - path: "src/validate.py"
      provides: "Pandera schema validation"
      exports: ["AIModelsSchema", "validate_data"]
  key_links:
    - from: "scripts/01_load.py"
      to: "data/raw/ai_models_performance.csv"
      via: "polars.scan_csv"
      pattern: "scan_csv.*ai_models_performance"
    - from: "scripts/01_load.py"
      to: "src/validate.py"
      via: "schema validation call"
      pattern: "AIModelsSchema\\.validate"
    - from: "scripts/01_load.py"
      to: "data/interim/01_loaded.parquet"
      via: "sink_parquet checkpoint"
      pattern: "sink_parquet.*01_loaded"
---

<objective>
Load the AI models benchmark dataset with explicit schema validation and document its structure.

Purpose: Convert raw CSV into a validated Polars LazyFrame with proper data types, quarantining invalid records and creating a clean foundation for all downstream analysis.
Output: Loaded dataset saved as parquet checkpoint, schema validation report, and data structure documentation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline-&-quality-assessment**---load,-clean,-validate,-and-enrich-the-benchmark-dataset/01-CONTEXT.md
@.planning/phases/01-data-pipeline-&-quality-assessment**---load,-clean,-validate,-and-enrich-the-benchmark-dataset/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Implement schema validation with Pandera</name>
  <files>src/validate.py</files>
  <action>
    Create src/validate.py with Pandera schema validation:

    Import pandera.polars as pa and polars as pl

    Define `AIModelsSchema` class inheriting from `pa.DataFrameModel`:
    - `model: str = pa.Field(description="Model name")`
    - `context_window: int = pa.Field(ge=0, le=2_000_000, description="Context window size in tokens")`
    - `creator: str = pa.Field(description="Model creator/organization")`
    - `intelligence_index: int = pa.Field(ge=0, le=100, description="IQ score (0-100)")`
    - `price_usd: float = pa.Field(ge=0, description="Price per 1M tokens in USD")`
    - `speed: float = pa.Field(ge=0, description="Median tokens per second")`
    - `latency: float = pa.Field(ge=0, description="First chunk latency in seconds")`

    Add custom dataframe_check to validate context window range (realistic values 0 to 2M)

    Define `validate_data(df: pl.DataFrame) -> pl.DataFrame` function:
    - Convert schema to validation object
    - Run validation and return validated DataFrame
    - Raise SchemaError with detailed message if validation fails

    Reference RESEARCH.md Pattern 3 for exact implementation
    Add comprehensive docstrings explaining validation choices
  </action>
  <verify>
    `python -c "from src.validate import AIModelsSchema, validate_data; print('Schema imported')"` confirms module loads
  </verify>
  <done>
    src/validate.py exists with AIModelsSchema class and validate_data function that enforces type and range constraints
  </done>
</task>

<task type="auto">
  <name>Implement data loading with schema validation</name>
  <files>src/load.py, data/interim/01_loaded.parquet</files>
  <action>
    Create src/load.py with data loading utilities:

    Import polars as pl, src.validate, and src.utils

    Define `load_data(path: str) -> pl.LazyFrame` function:
    - Define explicit schema dict matching CSV columns:
      * "Model": pl.Utf8
      * "Context Window": pl.Int64
      * "Creator": pl.Utf8
      * "Intelligence Index": pl.Int64
      * "Price (Blended USD/1M Tokens)": pl.Utf8 (will clean to Float64 in plan 03)
      * "Speed(median token/s)": pl.Float64
      * "Latency (First Answer Chunk /s)": pl.Float64
    - Use pl.scan_csv with schema_overrides parameter
    - Return LazyFrame for lazy evaluation

    Define `document_structure(lf: pl.LazyFrame) -> dict` function:
    - Collect schema and sample data
    - Return dict with:
      * column_names: list of all columns
      * dtypes: dict mapping column names to Polars types
      * sample_values: first 5 rows as list of dicts
      * row_count: total number of rows
    - Print documentation to console with verbose logging

    Reference RESEARCH.md "Loading CSV with Explicit Schema" example
    Add comments explaining why Price column is Utf8 (needs cleaning in plan 03)

    Update scripts/01_load.py to:
    - Import load_data and document_structure from src.load
    - Load data from data/raw/ai_models_performance.csv
    - Document structure (print to console)
    - Collect and validate with Pandera schema
    - Quarantine any invalid rows to data/quarantine/01_invalid_records.csv
    - Save valid data to data/interim/01_loaded.parquet using sink_parquet

    Handle quoted multi-line values like "41\nE" by using Polars default CSV parser
  </action>
  <verify>
    `python scripts/01_load.py` runs successfully and outputs structure documentation
    `test -f data/interim/01_loaded.parquet` confirms checkpoint created
    `python -c "import polars as pl; df = pl.read_parquet('data/interim/01_loaded.parquet'); print(df.shape)"` shows (188, 7) or similar
  </verify>
  <done>
    Data is loaded with explicit schema, structure is documented with column names/types/samples, schema validation runs, and valid data is saved to parquet checkpoint with invalid records quarantined
  </done>
</task>

<task type="auto">
  <name>Generate data structure documentation report</name>
  <files>reports/data_structure.md</files>
  <action>
    Create reports/data_structure.md with comprehensive documentation:

    Include:
    - Dataset overview (source, row count, column count)
    - Column documentation table with:
      * Column name
      * Data type
      * Description
      * Valid range
      * Sample values (first 3)
    - Schema validation results (pass/fail, quarantined records if any)
    - Notes on data quality issues found during loading
    - Next steps (cleaning, validation, enrichment)

    Use document_structure() output to populate table
    Add narrative interpretation of findings
    Include timestamp and generation metadata

    Reference DATA-02 requirement for documentation format
  </action>
  <verify>
    `test -f reports/data_structure.md` confirms report exists
    `grep -q "Column name" reports/data_structure.md` confirms table structure
    `grep -q "Model" reports/data_structure.md` confirms content
  </verify>
  <done>
    Data structure documentation exists in markdown format with complete column descriptions, types, ranges, sample values, and validation results
  </done>
</task>

</tasks>

<verification>
- [ ] src/validate.py exists with AIModelsSchema class
- [ ] Schema validates all 7 columns with appropriate type and range constraints
- [ ] src/load.py exists with load_data and document_structure functions
- [ ] scripts/01_load.py imports from src.load and src.validate
- [ ] Running scripts/01_load.py completes without errors
- [ ] data/interim/01_loaded.parquet exists with validated data
- [ ] data/quarantine/01_invalid_records.csv exists if any invalid records found
- [ ] reports/data_structure.md exists with complete documentation
- [ ] Console output shows structure documentation during execution
</verification>

<success_criteria>
Raw CSV is loaded into Polars LazyFrame with explicit schema, data structure is comprehensively documented, schema validation is enforced with Pandera, and clean data is checkpointed to parquet format with any invalid records quarantined for review.
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline-&-quality-assessment**---load,-clean,-validate,-and-enrich-the-benchmark-dataset/01-02-SUMMARY.md`
</output>
