---
phase: 01-data-pipeline
plan: 04
type: execute
wave: 3
depends_on: [01-02]
files_modified:
  - data/interim/03_distributions_analyzed.parquet
  - src/analyze.py
  - scripts/03_analyze_distributions.py
  - reports/figures/
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Summary statistics are generated for all numerical variables"
    - "Distribution analysis includes histograms, skewness, and kurtosis"
    - "Outliers are detected using Isolation Forest and documented"
    - "Distribution visualizations are generated and saved to reports/figures/"
  artifacts:
    - path: "data/interim/03_distributions_analyzed.parquet"
      provides: "Dataset with outlier flags and statistics"
      format: "parquet"
    - path: "src/analyze.py"
      provides: "Statistical analysis utilities"
      exports: ["analyze_distribution", "detect_outliers_isolation_forest"]
    - path: "reports/figures/"
      provides: "Generated distribution and outlier visualizations"
      contains: "*.png"
  key_links:
    - from: "scripts/03_analyze_distributions.py"
      to: "data/interim/02_cleaned.parquet"
      via: "load cleaned data"
      pattern: "read_parquet.*02_cleaned"
    - from: "scripts/03_analyze_distributions.py"
      to: "src/analyze.py"
      via: "statistical analysis functions"
      pattern: "from src\\.analyze import"
    - from: "scripts/03_analyze_distributions.py"
      to: "reports/figures/"
      via: "save generated plots"
      pattern: "savefig.*reports/figures"
---

<objective>
Analyze data distributions and detect outliers using statistical methods and visualization.

Purpose: Understand the shape and spread of all numerical variables, identify anomalies that may indicate data quality issues or genuine outliers, and create visual diagnostics for data quality assessment.
Output: Comprehensive distribution analysis report, outlier detection results, and generated visualizations saved to reports/figures/.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline-&-quality-assessment**---load,-clean,-validate,-and-enrich-the-benchmark-dataset/01-CONTEXT.md
@.planning/phases/01-data-pipeline-&-quality-assessment**---load,-clean,-validate,-and-enrich-the-benchmark-dataset/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Implement distribution analysis functions</name>
  <files>src/analyze.py</files>
  <action>
    Create src/analyze.py with statistical analysis utilities:

    Import scipy.stats, numpy as np, polars as pl

    Define `analyze_distribution(series: pl.Series) -> dict` function:
    - Drop null values from series
    - Convert to numpy array
    - Calculate and return dict with:
      * count: number of non-null values
      * mean: arithmetic mean
      * std: standard deviation
      * min: minimum value
      * max: maximum value
      * median: 50th percentile
      * q25: 25th percentile
      * q75: 75th percentile
      * skewness: scipy.stats.skew() - measure of asymmetry
      * kurtosis: scipy.stats.kurtosis(fisher=False) - measure of tail heaviness
      * normality_test: scipy.stats.normaltest() - tests if distribution is Gaussian

    Reference RESEARCH.md "Statistical Distribution Analysis" example
    Add docstring explaining each statistic and its interpretation
    Add type hints for all parameters and returns
  </action>
  <verify>
    `python -c "from src.analyze import analyze_distribution; print('Function imported')"` confirms function exists
  </verify>
  <done>
    analyze_distribution function exists that calculates comprehensive statistics including mean, std, skewness, kurtosis, and normality test
  </done>
</task>

<task type="auto">
  <name>Implement Isolation Forest outlier detection</name>
  <files>src/analyze.py</files>
  <action>
    Add to src/analyze.py:

    Import sklearn.ensemble.IsolationForest

    Define `detect_outliers_isolation_forest(df: pl.DataFrame, columns: list[str], contamination: float = 0.05) -> pl.DataFrame` function:
    - Extract numerical features from specified columns
    - Convert to numpy array
    - Initialize IsolationForest with:
      * contamination=0.05 (expect 5% outliers - adjust based on data)
      * random_state=42 (reproducibility)
      * n_jobs=-1 (use all CPU cores)
    - Fit model on data
    - Predict outliers: -1 for outliers, 1 for inliers
    - Calculate outlier scores (anomaly scores)
    - Add columns to DataFrame:
      * is_outlier: boolean (True for outliers)
      * outlier_score: float (lower = more anomalous)
    - Return DataFrame with outlier flags

    Reference RESEARCH.md "Outlier Detection with Isolation Forest" example
    Add docstring explaining Isolation Forest advantages over IQR/z-score
    Add comments explaining contamination parameter choice

    Note: According to CONTEXT.md, use Claude's discretion for handling anomalies - flag outliers but do not automatically remove (will be documented in quality report)
  </action>
  <verify>
    `python -c "from src.analyze import detect_outliers_isolation_forest; print('Function imported')"` confirms function exists
  </verify>
  <done>
    detect_outliers_isolation_forest function exists that uses sklearn Isolation Forest to detect multivariate outliers and flag them with scores
  </done>
</task>

<task type="auto">
  <name>Implement distribution visualization functions</name>
  <files>src/analyze.py</files>
  <action>
    Add to src/analyze.py:

    Import matplotlib.pyplot as plt, seaborn as sns

    Define `plot_distribution(df: pl.DataFrame, column: str, output_path: str)` function:
    - Extract column data and drop nulls
    - Create figure with 3 subplots (1 row, 3 columns)
    - Subplot 1: Histogram with KDE curve using seaborn.histplot
    - Subplot 2: Box plot using seaborn.boxplot
    - Subplot 3: Q-Q plot for normality using scipy.stats.probplot
    - Add titles and labels to each subplot
    - Use tight_layout() to prevent overlapping
    - Save to output_path with dpi=300, bbox_inches="tight"
    - Close figure to free memory

    Define `plot_all_distributions(df: pl.DataFrame, columns: list[str], output_dir: str)` function:
    - Loop through each numerical column
    - Call plot_distribution() for each
    - Save each plot as {column}_distribution.png in output_dir

    Reference RESEARCH.md "Distribution Visualization" example
    Add docstrings with examples of generated plots
  </action>
  <verify>
    `python -c "from src.analyze import plot_distribution, plot_all_distributions; print('Functions imported')"` confirms functions exist
  </verify>
  <done>
    Distribution visualization functions exist that generate histogram+KDE, box plot, and Q-Q plot for any numerical column
  </done>
</task>

<task type="auto">
  <name>Execute distribution analysis and generate visualizations</name>
  <files>scripts/03_analyze_distributions.py, data/interim/03_distributions_analyzed.parquet</files>
  <action>
    Update scripts/03_analyze_distributions.py to execute full analysis:

    Import functions from src.analyze and src.utils
    Import polars as pl

    Pipeline steps:
    1. Load checkpoint from data/interim/02_cleaned.parquet
    2. Define numerical columns to analyze:
       * context_window
       * intelligence_index
       * price_usd
       * speed
       * latency
    3. For each column:
       * Calculate distribution statistics using analyze_distribution()
       * Print summary to console (mean, std, skewness, kurtosis)
       * Generate distribution plot using plot_distribution()
       * Save to reports/figures/{column}_distribution.png
    4. Detect outliers using detect_outliers_isolation_forest() on all numerical columns
    5. Add outlier flags to DataFrame
    6. Save to data/interim/03_distributions_analyzed.parquet using sink_parquet
    7. Print outlier summary:
       * Total outliers detected
       * Outlier percentage
       * Columns with most outliers
    8. Create reports/distributions.md with:
       * Statistics table for all numerical variables
       * Distribution interpretation (normal, skewed, multimodal?)
       * Outlier analysis results
       * Links to generated figures

    Use verbose logging at each step
    Document any anomalies or unexpected findings in comments
    Handle exceptions gracefully: if visualization fails for a column, log error and continue

    Reference RESEARCH.md "Statistical Distribution Analysis" and "Distribution Visualization" examples
  </action>
  <verify>
    `python scripts/03_analyze_distributions.py` runs successfully
    `test -f data/interim/03_distributions_analyzed.parquet` confirms checkpoint created
    `ls reports/figures/*.png | wc -l` shows at least 5 distribution plots (one per numerical column)
    `test -f reports/distributions.md` confirms analysis report exists
  </verify>
  <done>
    Distribution analysis completes for all numerical variables, statistics are calculated and documented, outliers are detected and flagged, and visualizations are generated and saved to reports/figures/
  </done>
</task>

</tasks>

<verification>
- [ ] src/analyze.py exists with all analysis functions
- [ ] analyze_distribution function calculates mean, std, skewness, kurtosis, normality test
- [ ] detect_outliers_isolation_forest function uses sklearn Isolation Forest
- [ ] plot_distribution function generates histogram+KDE, box plot, Q-Q plot
- [ ] scripts/03_analyze_distributions.py imports from src.analyze
- [ ] Running scripts/03_analyze_distributions.py completes without errors
- [ ] data/interim/03_distributions_analyzed.parquet exists with outlier flags
- [ ] reports/figures/ contains PNG files for all numerical columns
- [ ] reports/distributions.md exists with complete statistics and analysis
- [ ] Console output shows distribution summaries and outlier counts
</verification>

<success_criteria>
All numerical variables are analyzed with comprehensive statistics (mean, std, skewness, kurtosis, normality test), outliers are detected using Isolation Forest algorithm, and distribution visualizations are generated and saved for data quality assessment.
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline-&-quality-assessment**---load,-clean,-validate,-and-enrich-the-benchmark-dataset/01-04-SUMMARY.md`
</output>
