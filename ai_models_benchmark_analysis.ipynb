{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Models Benchmark 2026: A Data-Driven Analysis of Performance, Price, and Tradeoffs\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "**What if you could identify the best AI model for your use case in minutes, not days?**\n",
        "\n",
        "This notebook analyzes 187 AI models across 37 providers to uncover pricing patterns, performance correlations, and market dynamics that can inform your model selection strategy.\n",
        "\n",
        "### Key Insights\n",
        "\n",
        "- **Intelligence correlates moderately with price (\u03c1=0.590), but value champions exist** - You don't always need to pay premium prices for high intelligence. Budget-friendly models like DeepSeek V3.2 (IQ=41, $0.32) and GLM-4.7 (IQ=42, $0.94) offer competitive intelligence at a fraction of the cost.\n",
        "\n",
        "- **Only 8 models (4.4%) are Pareto-efficient for price-performance** - These models represent the \"efficient frontier\" where no other model offers higher intelligence at a lower price. The rest are either dominated by more capable models or overpriced for their performance.\n",
        "\n",
        "- **Market has split into Budget (24 providers) vs Premium (12 providers) segments** - K-means clustering reveals two distinct market segments: Budget providers ($0.35, IQ=17.9) and Premium providers ($1.53, IQ=29.0) with 4x price difference and 62% intelligence gap.\n",
        "\n",
        "- **All 10 pairwise correlations significant - no null findings in dataset** - Every relationship between variables (Intelligence-Price, Speed-Latency, etc.) is statistically significant after FDR correction, suggesting a highly interconnected market with consistent pricing patterns.\n",
        "\n",
        "- **Regional differences: Europe fastest (142 token/s), US most expensive ($1.53)** - European models prioritize speed (142.3 tokens/s) while US commands premium pricing ($1.53). Chinese models offer middle-ground pricing ($0.93) with competitive intelligence (22.2).\n",
        "\n",
        "### Methodology\n",
        "\n",
        "Analysis of 187 AI models across 37 providers using non-parametric statistics (Spearman correlation, Mann-Whitney U tests, bootstrap CIs). All visualizations are pre-generated for fast loading. Analysis code is modularized in `src/` for reproducibility.\n",
        "\n",
        "### Navigation\n",
        "\n",
        "Jump to: [Data Quality](#1-data-quality-assessment) | [Correlations](#2-correlation-analysis) | [Pareto Frontiers](#3-pareto-frontier-analysis) | [Provider Analysis](#4-provider-clustering) | [Conclusions](#5-conclusions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "This notebook imports pre-computed visualizations and analysis from our modular pipeline. No duplicate code - everything comes from `src/` modules and pre-generated reports.\n",
        "\n",
        "**Notebook structure:** All analysis logic lives in [src/](src/) modules for reproducibility. Visualizations are pre-generated for fast loading - see [reports/figures/](reports/figures/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "\n",
        "# Import analysis modules (script-as-module pattern)\n",
        "from src.load import load_data\n",
        "from src.analyze import analyze_distribution\n",
        "from src.statistics import compute_correlation_matrix, compute_spearman_correlation\n",
        "from src.pareto import get_pareto_efficient_models\n",
        "from src.clustering import aggregate_by_provider\n",
        "from src.bootstrap import bootstrap_mean_ci\n",
        "\n",
        "# Visualization helpers\n",
        "from IPython.display import IFrame, HTML, Markdown\n",
        "\n",
        "# Load data (use Polars directly for parquet files)\n",
        "df = pl.read_parquet(\"data/processed/ai_models_deduped.parquet\")\n",
        "\n",
        "print(f\"\u2713 Loaded {df.height} models\")\n",
        "print(f\"\u2713 {df['Creator'].n_unique()} providers represented\")\n",
        "print(f\"\u2713 Analysis modules ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Quality Assessment\n",
        "\n",
        "Before diving into insights, let's establish trust in our data foundation. A robust analysis requires a clean, validated dataset.\n",
        "\n",
        "### Quality Score Overview\n",
        "\n",
        "**Overall Quality Score: 75%** (3/4 dimensions passed)\n",
        "\n",
        "Our data quality assessment evaluated 6 dimensions: Accuracy, Completeness, Consistency, Validity, Integrity, and Timeliness. The dataset passed 3 of 4 applicable dimensions.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "| Metric | Value | Status |\n",
        "|--------|-------|--------|\n",
        "| **Models after deduplication** | 187 | 34 duplicate names resolved |\n",
        "| **Data completeness** | 96.81% | Only 6 null values in intelligence_index |\n",
        "| **Providers represented** | 37 | Across US, China, Europe, and other regions |\n",
        "| **Distribution characteristics** | Right-skewed | Validated non-parametric approach |\n",
        "| **Models flagged as outliers** | 10 (5.32%) | Preserved for analysis, not removed |\n",
        "\n",
        "### What This Means\n",
        "\n",
        "Our analysis is based on a clean, validated dataset with minimal missing values. The 6 models lacking intelligence scores represent models without IQ assessments (not data entry errors), so intelligence-specific analyses filter to 181 models. The 34 duplicate model names were resolved using context window disambiguation, ensuring accurate group-by operations.\n",
        "\n",
        "**Data quality note:** 10 models (5.32%) were flagged as outliers via Isolation Forest detection but preserved for analysis. These may represent legitimate high-performance models rather than data errors.\n",
        "\n",
        "See [full quality assessment](reports/quality_2026-01-18.md) for complete analysis including distribution statistics and outlier details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Methodology Note\n",
        "\n",
        "**Why we use Spearman correlation (non-parametric):** All numerical variables are right-skewed (skewness > 0), violating normality assumptions required for parametric tests like Pearson correlation. Spearman rank correlation is robust to non-normal distributions and outliers, making it the appropriate choice for this dataset.\n",
        "\n",
        "**Data distribution characteristics:**\n",
        "- Intelligence Index: Approximately normal (skewness=0.67)\n",
        "- Price, Speed, Latency: Moderately to highly right-skewed (1.73 - 7.11)\n",
        "- Context Window: Extremely right-skewed (skewness=9.63, kurtosis=114.20)\n",
        "\n",
        "This non-normality justifies our non-parametric approach throughout the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Correlation Analysis: What's Related to What?\n",
        "\n",
        "Smart models cost more - but how much more? And what else drives price?\n",
        "\n",
        "### Key Finding: Intelligence and Price\n",
        "\n",
        "**Intelligence and Price show moderate correlation (\u03c1=0.590)** - but this means there's room for value plays. Not all smart models are expensive, and not all expensive models are smart.\n",
        "\n",
        "| Variables | Correlation | Interpretation |\n",
        "|-----------|-------------|----------------|\n",
        "| Intelligence \u2194 Price | \u03c1=0.590 | Moderate positive |\n",
        "| Intelligence \u2194 Context Window | \u03c1=0.542 | Moderate positive |\n",
        "| Intelligence \u2194 Speed | \u03c1=0.261 | Weak positive |\n",
        "| Intelligence \u2194 Latency | \u03c1=0.444 | Moderate positive |\n",
        "\n",
        "**So what?** Smarter models tend to cost more and have larger context windows, but speed isn't strongly tied to intelligence. This means you **CAN** find fast models that are also smart.\n",
        "\n",
        "### Methodology\n",
        "\n",
        "We used **Spearman correlation** (non-parametric) because our data is right-skewed. All 10 pairwise correlations were statistically significant after FDR correction (False Discovery Rate).\n",
        "\n",
        "**Null findings:** None - every correlation we tested was significant, suggesting this market has consistent patterns.\n",
        "\n",
        "See [full correlation analysis](reports/correlation_analysis_2026-01-18.md) for complete statistical details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-computed correlation matrix\n",
        "corr_matrix = compute_spearman_correlation(df, 'intelligence_index', ['price_usd', 'Speed(median token/s)', 'Latency (First Answer Chunk /s)', 'context_window'])\n",
        "\n",
        "print(\"Correlation matrix loaded from analysis pipeline\")\n",
        "print(f\"\\nIntelligence-Price correlation: {corr_matrix['intelligence_index']['price_usd']:.3f}\")\n",
        "print(f\"Intelligence-Speed correlation: {corr_matrix['intelligence_index']['Speed(median token/s)']:.3f}\")\n",
        "print(f\"Intelligence-Context Window correlation: {corr_matrix['intelligence_index']['context_window']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation Heatmap\n",
        "\n",
        "See how variables cluster together:\n",
        "\n",
        "**What the heatmap shows:** Red = positive correlation, Blue = negative (we have none)\n",
        "\n",
        "**Hierarchical clustering groups:** {Intelligence, Price, Context Window} form one cluster, {Speed, Latency} form another.\n",
        "\n",
        "**Practical implication:** If you need high intelligence, expect higher prices and larger context windows. But speed is separable - you can find fast OR slow smart models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display pre-generated correlation heatmap\n",
        "IFrame(src='reports/figures/interactive_correlation_heatmap.html', width=800, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Pareto Frontier Analysis: The Efficient Frontier\n",
        "\n",
        "Which models offer the best tradeoffs? Pareto analysis identifies \"undominated\" choices - models where no other option is better in ALL dimensions.\n",
        "\n",
        "### What is Pareto Efficiency?\n",
        "\n",
        "A model is **Pareto-efficient** if improving one objective (e.g., intelligence) would require sacrificing another (e.g., price). These models form the \"efficient frontier\" of optimal choices.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "| Frontier | Efficient Models | What It Means |\n",
        "|----------|------------------|---------------|\n",
        "| Intelligence vs Price | 8 (4.4%) | Best value per dollar |\n",
        "| Speed vs Intelligence | 6 (3.3%) | Performance leaders |\n",
        "| Multi-objective | 41 (22.7%) | Balanced excellence |\n",
        "\n",
        "### Price-Performance Champions\n",
        "\n",
        "- **GPT-5.2:** IQ=51, $4.81 (premium leader)\n",
        "- **Gemini 3 Flash:** IQ=46, $1.13 (value leader)\n",
        "- **GLM-4.7:** IQ=42, $0.94 (budget champion)\n",
        "\n",
        "**So what?** Only 8 models (4.4%) are truly optimal for price-performance. If your chosen model isn't on this frontier, there's a better option at your price point.\n",
        "\n",
        "**Provider dominance:** OpenAI and Google each have 2 models on the price-performance frontier (25% each)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Pareto-efficient models for each frontier\n",
        "price_perf = get_pareto_efficient_models(df, 'intelligence_index', 'price_usd')\n",
        "speed_intel = get_pareto_efficient_models(df, 'Speed(median token/s)', 'intelligence_index')\n",
        "\n",
        "print(f\"Price-performance frontier: {len(price_perf)} models\")\n",
        "print(f\"Speed-intelligence frontier: {len(speed_intel)} models\")\n",
        "print(f\"\\nTop 3 price-performance champions:\")\n",
        "for model in price_perf.head(3).iter_rows(named=True):\n",
        "    print(f\"  - {model['Model']}: IQ={model['intelligence_index']}, ${model['price_usd']:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Price-Performance Frontier (Intelligence vs Price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IFrame(src='reports/figures/interactive_pareto_intelligence_price.html', width=800, height=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Speed-Intelligence Frontier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IFrame(src='reports/figures/interactive_pareto_speed_intelligence.html', width=800, height=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpreting the Frontiers\n",
        "\n",
        "- **Red markers = Pareto-efficient models** (best tradeoffs)\n",
        "- **What this means:** Choose models on the red frontier line. Everything below/right is dominated - there's a better option.\n",
        "\n",
        "### Model Selection Guide\n",
        "\n",
        "| Use Case | Which Frontier | Strategy |\n",
        "|----------|----------------|----------|\n",
        "| Budget apps | Intelligence vs Price | Pick from price-performance frontier |\n",
        "| Real-time apps | Speed vs Intelligence | Pick from speed-intelligence frontier |\n",
        "| Balanced needs | Multi-objective | Pick from multi-objective frontier |\n",
        "\n",
        "See [full Pareto analysis](reports/pareto_analysis_2026-01-18.md) for complete frontier details and model listings.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Provider Clustering: Market Segmentation\n",
        "\n",
        "The AI provider market has split into two distinct segments. Which one fits your needs?\n",
        "\n",
        "### Key Finding: Two Market Segments\n",
        "\n",
        "**KMeans clustering (K=2, silhouette=0.390)** reveals Budget-Friendly vs Premium Performance segments:\n",
        "\n",
        "| Segment | Providers | Mean IQ | Mean Price | Mean Speed |\n",
        "|---------|-----------|---------|------------|------------|\n",
        "| **Budget-Friendly** | 24 (67%) | 17.9 | $0.35 | 34 token/s |\n",
        "| **Premium Performance** | 12 (33%) | 29.0 | $1.53 | 117 token/s |\n",
        "\n",
        "**Budget providers:** Alibaba, DeepSeek, Meta, Microsoft, Baidu, IBM, NVIDIA, Perplexity (+16 others)\n",
        "\n",
        "**Premium providers:** OpenAI, Anthropic, Google, Amazon, Mistral, Cohere, xAI (+5 others)\n",
        "\n",
        "**So what?** Premium providers offer 62% higher intelligence (29.0 vs 17.9) but cost 4.4x more. Budget segment is better for cost-sensitive applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load provider-level aggregates and regional comparisons\n",
        "providers = aggregate_by_provider(df)\n",
        "regional = compare_regions(df)\n",
        "\n",
        "print(f\"Providers analyzed: {len(providers)}\")\n",
        "print(f\"Regions: US, China, Europe, Other\")\n",
        "print(f\"\\nRegional Intelligence (mean):\")\n",
        "for region, stats in regional.groupby('region').agg({'intelligence_index': 'mean'}).iter_rows(named=True):\n",
        "    print(f\"  {region['region']}: {region['intelligence_index']:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regional Analysis\n",
        "\n",
        "How do regions compare across key metrics?\n",
        "\n",
        "| Region | Intelligence | Price | Speed |\n",
        "|--------|--------------|-------|-------|\n",
        "| **China** | 22.2 | $0.93 | 66 token/s |\n",
        "| **US** | 22.6 | $1.53 | 118 token/s |\n",
        "| **Europe** | 18.8 | $0.55 | 142 token/s |\n",
        "\n",
        "**Regional insight:** European models are fastest but cheapest. US models are most expensive. Chinese models balance speed and price.\n",
        "\n",
        "### Provider Comparison Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IFrame(src='reports/figures/interactive_provider_dashboard.html', width=900, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpreting the Dashboard\n",
        "\n",
        "**Scatter panels show:** Intelligence-Price, Intelligence-Speed, Price-Speed relationships with cluster color-coding.\n",
        "\n",
        "**Gold stars = Cluster centroids** (typical provider for each segment)\n",
        "\n",
        "**What this means:**\n",
        "- **Cluster 0 (blue):** Budget-friendly options - good for high-volume, cost-sensitive apps\n",
        "- **Cluster 1 (red):** Premium performance - good for intelligence-critical applications\n",
        "\n",
        "**Strategic implication:** Choose your segment first (budget vs premium), then pick the best model within that segment using Pareto analysis.\n",
        "\n",
        "See [full provider clustering analysis](reports/provider_clustering_2026-01-18.md) for complete regional and segment details.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Speed-Intelligence Tradeoff: Choose Your Zone\n",
        "\n",
        "**Real-time chatbot or batch analysis? The speed-intelligence tradeoff defines your use case.**\n",
        "\n",
        "We identified **4 use case zones** based on speed and intelligence thresholds:\n",
        "\n",
        "| Zone | Speed | Intelligence | Best For |\n",
        "|------|-------|--------------|----------|\n",
        "| **Real-time** | >100 token/s | Any | Live chat, interactive apps |\n",
        "| **High-IQ** | Any | >40 | Complex reasoning, code gen |\n",
        "| **Balanced** | 50-100 | 20-40 | General-purpose apps |\n",
        "| **Budget** | <50 | <20 | Cost-sensitive, simple tasks |\n",
        "\n",
        "**Pareto-efficient speed-intelligence models:**\n",
        "- **Gemini 2.5 Flash-Lite:** 550 token/s (throughput leader)\n",
        "- **gpt-oss-120B:** 366 token/s, IQ=33\n",
        "- **o3:** 264 token/s, IQ=41\n",
        "- **GPT-5.2:** 100 token/s, IQ=51 (intelligence leader)\n",
        "\n",
        "**So what?** If you need real-time responses (>100 token/s), you have 6 Pareto-efficient options. If you need high intelligence (>40), expect to sacrifice speed or pay more.\n",
        "\n",
        "**Tradeoff insight:** Speed and intelligence have weak correlation (\u03c1=0.261). This means you **CAN** find fast models with good intelligence - they're rare but exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define use case zones\n",
        "real_time = df.filter(pl.col('Speed(median token/s)') > 100)\n",
        "high_iq = df.filter(pl.col('intelligence_index') > 40)\n",
        "balanced = df.filter(\n",
        "    (pl.col('Speed(median token/s)') >= 50) & (pl.col('Speed(median token/s)') <= 100) &\n",
        "    (pl.col('intelligence_index') >= 20) & (pl.col('intelligence_index') <= 40)\n",
        ")\n",
        "budget = df.filter(\n",
        "    (pl.col('Speed(median token/s)') < 50) & (pl.col('intelligence_index') < 20)\n",
        ")\n",
        "\n",
        "print(f\"Real-time zone: {len(real_time)} models\")\n",
        "print(f\"High-IQ zone: {len(high_iq)} models\")\n",
        "print(f\"Balanced zone: {len(balanced)} models\")\n",
        "print(f\"Budget zone: {len(budget)} models\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Speed-Intelligence Tradeoff with Use Case Zones\n",
        "\n",
        "**What the visualization shows:**\n",
        "- **Colored zones** show use case categories (semi-transparent overlays)\n",
        "- **Star markers** = Pareto-efficient models on the speed-intelligence frontier\n",
        "- **Each point** = one AI model positioned by speed and intelligence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IFrame(src='reports/figures/interactive_tradeoff_analysis.html', width=900, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpreting the Tradeoff Analysis\n",
        "\n",
        "**Zone meanings:**\n",
        "- **Bottom-left (Budget zone):** Cheap but slow and not very smart\n",
        "- **Top-left (High-IQ zone):** Smart but expensive and slower\n",
        "- **Bottom-right (Real-time zone):** Fast but mid-intelligence\n",
        "- **Top-right (Balanced zone):** Sweet spot for most applications\n",
        "\n",
        "**Model selection by zone:**\n",
        "- **Chatbots:** Choose from Real-time zone (Gemini 3 Flash, o3)\n",
        "- **Code generation:** Choose from High-IQ zone (GPT-5.2, Claude Opus)\n",
        "- **General apps:** Choose from Balanced zone (GPT-5 mini, GLM-4.7)\n",
        "- **Cost-sensitive:** Choose from Budget zone (DeepSeek V3.2, MiMo-V2-Flash)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 2027 Trend Predictions: What's Next?\n",
        "\n",
        "**If current trends continue, what will 2027 look like? Here are our scenario-based projections.**\n",
        "\n",
        "**Important:** These are simplified extrapolations from 2026 cross-sectional data, **NOT** sophisticated forecasts. We lack time series data, so we project using scenario analysis (optimistic/baseline/pessimistic).\n",
        "\n",
        "### Key Predictions by Scenario\n",
        "\n",
        "| Metric | 2026 | 2027 Optimistic | 2027 Baseline | 2027 Pessimistic |\n",
        "|--------|------|-----------------|---------------|------------------|\n",
        "| **Mean Intelligence** | 21.81 | 23.99 (+10%) | 22.90 (+5%) | 22.24 (+2%) |\n",
        "| **Mean Price** | $1.00 | -$20% | -10% | -5% |\n",
        "| **Mean Speed** | 90.7 token/s | +20% | +10% | +5% |\n",
        "\n",
        "**Directional trends (high confidence):**\n",
        "- **Intelligence:** modest increase (2-10%)\n",
        "- **Price:** decreasing (-5% to -20%) by tier\n",
        "- **Speed:** improving (+5% to +20%)\n",
        "\n",
        "**Uncertainty discussion:**\n",
        "- **Wide prediction intervals** reflect high uncertainty (e.g., 95% PI for intelligence: [1.2, 45.0])\n",
        "- **Cross-sectional limitation:** We have 2026 snapshot, not historical data from 2015-2026\n",
        "- **Black swan risk:** GPT-4 level breakthroughs are unpredictable and could accelerate trends\n",
        "- **Not for betting:** Use these for exploratory analysis, NOT investment decisions\n",
        "\n",
        "**So what?** Expect gradual improvement in intelligence and speed, with falling prices. But disruption is likely - these trends assume linear progress, which rarely holds in AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trend predictions are in the report, not recomputed here\n",
        "# See reports/trend_predictions_2026-01-18.md for full analysis\n",
        "\n",
        "from src.bootstrap import bootstrap_mean_ci\n",
        "\n",
        "# Show current 2026 statistics with 95% CIs\n",
        "iq_mean, iq_ci = bootstrap_mean_ci(df, 'intelligence_index', n_resamples=9999)\n",
        "price_mean, price_ci = bootstrap_mean_ci(df, 'price_usd', n_resamples=9999)\n",
        "speed_mean, speed_ci = bootstrap_mean_ci(df, 'Speed(median token/s)', n_resamples=9999)\n",
        "\n",
        "print(f\"2026 Intelligence: {iq_mean:.2f} [{iq_ci[0]:.2f}, {iq_ci[1]:.2f}]\")\n",
        "print(f\"2026 Price: ${price_mean:.2f} [${price_ci[0]:.2f}, ${price_ci[1]:.2f}]\")\n",
        "print(f\"2026 Speed: {speed_mean:.1f} token/s [{speed_ci[0]:.1f}, {speed_ci[1]:.1f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Full 2027 Predictions Report\n",
        "\n",
        "See [trend_predictions_2026-01-18.md](reports/trend_predictions_2026-01-18.md) for:\n",
        "- Detailed scenario assumptions\n",
        "- Prediction intervals by intelligence tier\n",
        "- Sources of uncertainty\n",
        "- Recommendations for using these predictions\n",
        "\n",
        "### Why These Predictions Are Unreliable\n",
        "\n",
        "**Methodological caveats:**\n",
        "- **No time series data** (single 2026 snapshot)\n",
        "- **Linear extrapolation** (technology follows S-curves, not lines)\n",
        "- **No disruption modeling** (breakthroughs change everything)\n",
        "- **Competitive dynamics** (new entrants like DeepSeek can disrupt quickly)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Conclusions and Recommendations\n",
        "\n",
        "### 7.1 Key Takeaways\n",
        "\n",
        "This analysis of 187 AI models across 37 providers reveals several critical insights:\n",
        "\n",
        "- **The AI market has split into two segments:** Budget-friendly (67% of providers) vs Premium Performance (33%)\n",
        "- **Only 4.4% of models** are Pareto-efficient for price-performance - most models are dominated\n",
        "- **All 10 correlations** we tested were statistically significant - this market has consistent patterns\n",
        "- **Intelligence costs more** (\u03c1=0.590) but value champions exist (Gemini 3 Flash: IQ=46, $1.13)\n",
        "- **Speed \u2260 Intelligence** (\u03c1=0.261) - you can find fast models that are also smart\n",
        "- **Regional differences:** Europe fastest, US most expensive, China balances both\n",
        "\n",
        "### 7.2 Practical Recommendations\n",
        "\n",
        "**For budget-constrained apps:** Choose Budget segment providers (DeepSeek, Meta, Microsoft) and Pareto-efficient models\n",
        "\n",
        "**For intelligence-critical apps:** Choose Premium segment (OpenAI, Anthropic, Google) and accept higher costs\n",
        "\n",
        "**For real-time applications:** Choose from Real-time zone (Gemini 3 Flash, o3) with >100 token/s\n",
        "\n",
        "**For general-purpose apps:** Choose from Balanced zone (GPT-5 mini, GLM-4.7) for best tradeoffs\n",
        "\n",
        "**For 2027 planning:** Expect modest improvements (+2-10% intelligence, +5-20% speed, -5 to -20% prices) but plan for disruption\n",
        "\n",
        "### 7.3 Novel Insights (Project Goal)\n",
        "\n",
        "**Market bifurcation:** Provider market has cleaved into Budget vs Premium segments (not continuous spectrum)\n",
        "\n",
        "**Pareto sparsity:** Only 8/181 models (4.4%) are price-performance efficient - most models are dominated choices\n",
        "\n",
        "**Speed-intelligence decoupling:** Weak correlation (\u03c1=0.261) means speed is separable from intelligence - enabling use case specialization\n",
        "\n",
        "**Regional asymmetry:** Europe fastest but cheapest, US most expensive - suggests different regional priorities\n",
        "\n",
        "### 7.4 Limitations\n",
        "\n",
        "- **Cross-sectional data:** Single 2026 snapshot, not time series\n",
        "- **Selection bias:** Dataset may not represent all models\n",
        "- **Correlation \u2260 causation:** All associations, not causal relationships (NARR-08)\n",
        "- **External validity:** Scores may vary by task and implementation\n",
        "- **Missing factors:** We don't measure ecosystem, documentation, ease of use\n",
        "\n",
        "### 7.5 Future Work\n",
        "\n",
        "- **Collect temporal data:** Track model releases over time for proper trend analysis\n",
        "- **Capability-specific benchmarks:** Separate scores for reasoning, coding, math, creative writing\n",
        "- **Cost optimization analysis:** Total cost of ownership (API + compute + latency)\n",
        "- **User satisfaction surveys:** Real-world usage vs benchmark scores\n",
        "- **Regulatory impact analysis:** How EU AI Act, US executive orders affect development\n",
        "\n",
        "### 7.6 Final Thoughts\n",
        "\n",
        "The AI model market is maturing. Clear segments have emerged, Pareto frontiers define optimal choices, and tradeoffs are well-understood. Use this analysis to narrow your search, then test models for your specific use case. The best model is the one that works for YOUR application, not the one with the highest benchmark score.\n",
        "\n",
        "**Question for you:** What use case are you optimizing for? Let us know in the comments!\n",
        "\n",
        "---\n",
        "\n",
        "**Thanks for reading!** If you found this analysis helpful, please upvote.\n",
        "\n",
        "Questions or feedback? Let me know in the comments!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}