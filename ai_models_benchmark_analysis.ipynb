{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Models Benchmark 2026: A Data-Driven Analysis of Performance, Price, and Tradeoffs\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "**What if you could identify the best AI model for your use case in minutes, not days?**\n",
    "\n",
    "This notebook analyzes 187 AI models across 37 providers to uncover pricing patterns, performance correlations, and market dynamics that can inform your model selection strategy.\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Intelligence correlates moderately with price (\u03c1=0.590), but value champions exist** - You don't always need to pay premium prices for high intelligence. Budget-friendly models like DeepSeek V3.2 (IQ=41, $0.32) and GLM-4.7 (IQ=42, $0.94) offer competitive intelligence at a fraction of the cost.\n",
    "\n",
    "- **Only 8 models (4.4%) are Pareto-efficient for price-performance** - These models represent the \"efficient frontier\" where no other model offers higher intelligence at a lower price. The rest are either dominated by more capable models or overpriced for their performance.\n",
    "\n",
    "- **Market has split into Budget (24 providers) vs Premium (12 providers) segments** - K-means clustering reveals two distinct market segments: Budget providers ($0.35, IQ=17.9) and Premium providers ($1.53, IQ=29.0) with 4x price difference and 62% intelligence gap.\n",
    "\n",
    "- **All 10 pairwise correlations significant - no null findings in dataset** - Every relationship between variables (Intelligence-Price, Speed-Latency, etc.) is statistically significant after FDR correction, suggesting a highly interconnected market with consistent pricing patterns.\n",
    "\n",
    "- **Regional differences: Europe fastest (142 token/s), US most expensive ($1.53)** - European models prioritize speed (142.3 tokens/s) while US commands premium pricing ($1.53). Chinese models offer middle-ground pricing ($0.93) with competitive intelligence (22.2).\n",
    "\n",
    "### Methodology\n",
    "\n",
    "Analysis of 187 AI models across 37 providers using non-parametric statistics (Spearman correlation, Mann-Whitney U tests, bootstrap CIs). All visualizations are pre-generated for fast loading. Analysis code is modularized in `src/` for reproducibility.\n",
    "\n",
    "### Navigation\n",
    "\n",
    "Jump to: [Data Quality](#1-data-quality-assessment) | [Correlations](#2-correlation-analysis) | [Pareto Frontiers](#3-pareto-frontier-analysis) | [Provider Analysis](#4-provider-clustering) | [Conclusions](#5-conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook imports pre-computed visualizations and analysis from our modular pipeline. No duplicate code - everything comes from `src/` modules and pre-generated reports.\n",
    "\n",
    "**Notebook structure:** All analysis logic lives in [src/](src/) modules for reproducibility. Visualizations are pre-generated for fast loading - see [reports/figures/](reports/figures/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import analysis modules (script-as-module pattern)\n",
    "from src.load import load_data\n",
    "from src.analyze import analyze_distribution\n",
    "from src.statistics import compute_correlation_matrix, compute_spearman_correlation\n",
    "from src.pareto import get_pareto_efficient_models\n",
    "from src.clustering import aggregate_by_provider\n",
    "from src.bootstrap import bootstrap_mean_ci\n",
    "\n",
    "# Visualization helpers\n",
    "from IPython.display import IFrame, HTML, Markdown\n",
    "\n",
    "# Load data (use Polars directly for parquet files)\n",
    "df = pl.read_parquet(\"data/processed/ai_models_deduped.parquet\")\n",
    "\n",
    "print(f\"\u2713 Loaded {df.height} models\")\n",
    "print(f\"\u2713 {df['Creator'].n_unique()} providers represented\")\n",
    "print(f\"\u2713 Analysis modules ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Quality Assessment\n",
    "\n",
    "Before diving into insights, let's establish trust in our data foundation. A robust analysis requires a clean, validated dataset.\n",
    "\n",
    "### Quality Score Overview\n",
    "\n",
    "**Overall Quality Score: 75%** (3/4 dimensions passed)\n",
    "\n",
    "Our data quality assessment evaluated 6 dimensions: Accuracy, Completeness, Consistency, Validity, Integrity, and Timeliness. The dataset passed 3 of 4 applicable dimensions.\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "| Metric | Value | Status |\n",
    "|--------|-------|--------|\n",
    "| **Models after deduplication** | 187 | 34 duplicate names resolved |\n",
    "| **Data completeness** | 96.81% | Only 6 null values in intelligence_index |\n",
    "| **Providers represented** | 37 | Across US, China, Europe, and other regions |\n",
    "| **Distribution characteristics** | Right-skewed | Validated non-parametric approach |\n",
    "| **Models flagged as outliers** | 10 (5.32%) | Preserved for analysis, not removed |\n",
    "\n",
    "### What This Means\n",
    "\n",
    "Our analysis is based on a clean, validated dataset with minimal missing values. The 6 models lacking intelligence scores represent models without IQ assessments (not data entry errors), so intelligence-specific analyses filter to 181 models. The 34 duplicate model names were resolved using context window disambiguation, ensuring accurate group-by operations.\n",
    "\n",
    "**Data quality note:** 10 models (5.32%) were flagged as outliers via Isolation Forest detection but preserved for analysis. These may represent legitimate high-performance models rather than data errors.\n",
    "\n",
    "See [full quality assessment](reports/quality_2026-01-18.md) for complete analysis including distribution statistics and outlier details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology Note\n",
    "\n",
    "**Why we use Spearman correlation (non-parametric):** All numerical variables are right-skewed (skewness > 0), violating normality assumptions required for parametric tests like Pearson correlation. Spearman rank correlation is robust to non-normal distributions and outliers, making it the appropriate choice for this dataset.\n",
    "\n",
    "**Data distribution characteristics:**\n",
    "- Intelligence Index: Approximately normal (skewness=0.67)\n",
    "- Price, Speed, Latency: Moderately to highly right-skewed (1.73 - 7.11)\n",
    "- Context Window: Extremely right-skewed (skewness=9.63, kurtosis=114.20)\n",
    "\n",
    "This non-normality justifies our non-parametric approach throughout the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Analysis: What's Related to What?\n",
    "\n",
    "Smart models cost more - but how much more? And what else drives price?\n",
    "\n",
    "### Key Finding: Intelligence and Price\n",
    "\n",
    "**Intelligence and Price show moderate correlation (\u03c1=0.590)** - but this means there's room for value plays. Not all smart models are expensive, and not all expensive models are smart.\n",
    "\n",
    "| Variables | Correlation | Interpretation |\n",
    "|-----------|-------------|----------------|\n",
    "| Intelligence \u2194 Price | \u03c1=0.590 | Moderate positive |\n",
    "| Intelligence \u2194 Context Window | \u03c1=0.542 | Moderate positive |\n",
    "| Intelligence \u2194 Speed | \u03c1=0.261 | Weak positive |\n",
    "| Intelligence \u2194 Latency | \u03c1=0.444 | Moderate positive |\n",
    "\n",
    "**So what?** Smarter models tend to cost more and have larger context windows, but speed isn't strongly tied to intelligence. This means you **CAN** find fast models that are also smart.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "We used **Spearman correlation** (non-parametric) because our data is right-skewed. All 10 pairwise correlations were statistically significant after FDR correction (False Discovery Rate).\n",
    "\n",
    "**Null findings:** None - every correlation we tested was significant, suggesting this market has consistent patterns.\n",
    "\n",
    "See [full correlation analysis](reports/correlation_analysis_2026-01-18.md) for complete statistical details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed correlation matrix\n",
    "corr_matrix = compute_spearman_correlation(df, 'intelligence_index', ['price_usd', 'Speed(median token/s)', 'Latency (First Answer Chunk /s)', 'context_window'])\n",
    "\n",
    "print(\"Correlation matrix loaded from analysis pipeline\")\n",
    "print(f\"\\nIntelligence-Price correlation: {corr_matrix['intelligence_index']['price_usd']:.3f}\")\n",
    "print(f\"Intelligence-Speed correlation: {corr_matrix['intelligence_index']['Speed(median token/s)']:.3f}\")\n",
    "print(f\"Intelligence-Context Window correlation: {corr_matrix['intelligence_index']['context_window']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap\n",
    "\n",
    "See how variables cluster together:\n",
    "\n",
    "**What the heatmap shows:** Red = positive correlation, Blue = negative (we have none)\n",
    "\n",
    "**Hierarchical clustering groups:** {Intelligence, Price, Context Window} form one cluster, {Speed, Latency} form another.\n",
    "\n",
    "**Practical implication:** If you need high intelligence, expect higher prices and larger context windows. But speed is separable - you can find fast OR slow smart models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display pre-generated correlation heatmap\n",
    "IFrame(src='reports/figures/interactive_correlation_heatmap.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pareto Frontier Analysis: The Efficient Frontier\n",
    "\n",
    "Which models offer the best tradeoffs? Pareto analysis identifies \"undominated\" choices - models where no other option is better in ALL dimensions.\n",
    "\n",
    "### What is Pareto Efficiency?\n",
    "\n",
    "A model is **Pareto-efficient** if improving one objective (e.g., intelligence) would require sacrificing another (e.g., price). These models form the \"efficient frontier\" of optimal choices.\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "| Frontier | Efficient Models | What It Means |\n",
    "|----------|------------------|---------------|\n",
    "| Intelligence vs Price | 8 (4.4%) | Best value per dollar |\n",
    "| Speed vs Intelligence | 6 (3.3%) | Performance leaders |\n",
    "| Multi-objective | 41 (22.7%) | Balanced excellence |\n",
    "\n",
    "### Price-Performance Champions\n",
    "\n",
    "- **GPT-5.2:** IQ=51, $4.81 (premium leader)\n",
    "- **Gemini 3 Flash:** IQ=46, $1.13 (value leader)\n",
    "- **GLM-4.7:** IQ=42, $0.94 (budget champion)\n",
    "\n",
    "**So what?** Only 8 models (4.4%) are truly optimal for price-performance. If your chosen model isn't on this frontier, there's a better option at your price point.\n",
    "\n",
    "**Provider dominance:** OpenAI and Google each have 2 models on the price-performance frontier (25% each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pareto-efficient models for each frontier\n",
    "price_perf = get_pareto_efficient_models(df, 'intelligence_index', 'price_usd')\n",
    "speed_intel = get_pareto_efficient_models(df, 'Speed(median token/s)', 'intelligence_index')\n",
    "\n",
    "print(f\"Price-performance frontier: {len(price_perf)} models\")\n",
    "print(f\"Speed-intelligence frontier: {len(speed_intel)} models\")\n",
    "print(f\"\\nTop 3 price-performance champions:\")\n",
    "for model in price_perf.head(3).iter_rows(named=True):\n",
    "    print(f\"  - {model['Model']}: IQ={model['intelligence_index']}, ${model['price_usd']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price-Performance Frontier (Intelligence vs Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='reports/figures/interactive_pareto_intelligence_price.html', width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed-Intelligence Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='reports/figures/interactive_pareto_speed_intelligence.html', width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Frontiers\n",
    "\n",
    "- **Red markers = Pareto-efficient models** (best tradeoffs)\n",
    "- **What this means:** Choose models on the red frontier line. Everything below/right is dominated - there's a better option.\n",
    "\n",
    "### Model Selection Guide\n",
    "\n",
    "| Use Case | Which Frontier | Strategy |\n",
    "|----------|----------------|----------|\n",
    "| Budget apps | Intelligence vs Price | Pick from price-performance frontier |\n",
    "| Real-time apps | Speed vs Intelligence | Pick from speed-intelligence frontier |\n",
    "| Balanced needs | Multi-objective | Pick from multi-objective frontier |\n",
    "\n",
    "See [full Pareto analysis](reports/pareto_analysis_2026-01-18.md) for complete frontier details and model listings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Provider Clustering: Market Segmentation\n",
    "\n",
    "The AI provider market has split into two distinct segments. Which one fits your needs?\n",
    "\n",
    "### Key Finding: Two Market Segments\n",
    "\n",
    "**KMeans clustering (K=2, silhouette=0.390)** reveals Budget-Friendly vs Premium Performance segments:\n",
    "\n",
    "| Segment | Providers | Mean IQ | Mean Price | Mean Speed |\n",
    "|---------|-----------|---------|------------|------------|\n",
    "| **Budget-Friendly** | 24 (67%) | 17.9 | $0.35 | 34 token/s |\n",
    "| **Premium Performance** | 12 (33%) | 29.0 | $1.53 | 117 token/s |\n",
    "\n",
    "**Budget providers:** Alibaba, DeepSeek, Meta, Microsoft, Baidu, IBM, NVIDIA, Perplexity (+16 others)\n",
    "\n",
    "**Premium providers:** OpenAI, Anthropic, Google, Amazon, Mistral, Cohere, xAI (+5 others)\n",
    "\n",
    "**So what?** Premium providers offer 62% higher intelligence (29.0 vs 17.9) but cost 4.4x more. Budget segment is better for cost-sensitive applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load provider-level aggregates and regional comparisons\n",
    "providers = aggregate_by_provider(df)\n",
    "regional = compare_regions(df)\n",
    "\n",
    "print(f\"Providers analyzed: {len(providers)}\")\n",
    "print(f\"Regions: US, China, Europe, Other\")\n",
    "print(f\"\\nRegional Intelligence (mean):\")\n",
    "for region, stats in regional.groupby('region').agg({'intelligence_index': 'mean'}).iter_rows(named=True):\n",
    "    print(f\"  {region['region']}: {region['intelligence_index']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional Analysis\n",
    "\n",
    "How do regions compare across key metrics?\n",
    "\n",
    "| Region | Intelligence | Price | Speed |\n",
    "|--------|--------------|-------|-------|\n",
    "| **China** | 22.2 | $0.93 | 66 token/s |\n",
    "| **US** | 22.6 | $1.53 | 118 token/s |\n",
    "| **Europe** | 18.8 | $0.55 | 142 token/s |\n",
    "\n",
    "**Regional insight:** European models are fastest but cheapest. US models are most expensive. Chinese models balance speed and price.\n",
    "\n",
    "### Provider Comparison Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='reports/figures/interactive_provider_dashboard.html', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Dashboard\n",
    "\n",
    "**Scatter panels show:** Intelligence-Price, Intelligence-Speed, Price-Speed relationships with cluster color-coding.\n",
    "\n",
    "**Gold stars = Cluster centroids** (typical provider for each segment)\n",
    "\n",
    "**What this means:**\n",
    "- **Cluster 0 (blue):** Budget-friendly options - good for high-volume, cost-sensitive apps\n",
    "- **Cluster 1 (red):** Premium performance - good for intelligence-critical applications\n",
    "\n",
    "**Strategic implication:** Choose your segment first (budget vs premium), then pick the best model within that segment using Pareto analysis.\n",
    "\n",
    "See [full provider clustering analysis](reports/provider_clustering_2026-01-18.md) for complete regional and segment details.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "This analysis of 187 AI models across 37 providers reveals a market with clear patterns:\n",
    "\n",
    "1. **Value exists at all price points** - The moderate Intelligence-Price correlation (\u03c1=0.590) means you don't have to pay top dollar for high intelligence. Budget champions like GLM-4.7 (IQ=42, $0.94) compete well against premium models.\n",
    "\n",
    "2. **Most models are dominated** - Only 4.4% of models are Pareto-efficient for price-performance. If your model isn't on the frontier, there's a better option.\n",
    "\n",
    "3. **Market has bifurcated** - Two clear segments: Budget (67% of providers) and Premium (33%). Premium offers 62% higher intelligence for 4.4x the cost.\n",
    "\n",
    "4. **All variables are interconnected** - Every correlation was statistically significant, suggesting consistent market dynamics rather than random pricing.\n",
    "\n",
    "5. **Regional differences matter** - European models prioritize speed, US commands premium pricing, Chinese models offer balance.\n",
    "\n",
    "### How to Choose a Model\n",
    "\n",
    "1. **Define your priorities:** Budget vs. Intelligence vs. Speed\n",
    "2. **Pick your segment:** Budget-friendly or Premium Performance\n",
    "3. **Check the frontier:** Use Pareto analysis to find undominated models\n",
    "4. **Validate:** Consider qualitative factors (ecosystem, documentation, support)\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- **Cross-sectional data:** Single snapshot in time (2026)\n",
    "- **Benchmark-specific:** Intelligence scores may vary by task\n",
    "- **Price changes:** Prices are dynamic and may change\n",
    "\n",
    "### Future Research\n",
    "\n",
    "- **Trend analysis:** Track how correlations evolve over time\n",
    "- **Task-specific benchmarks:** Correlation may vary by use case\n",
    "- **Cost optimization:** Total cost of ownership including latency\n",
    "\n",
    "---\n",
    "\n",
    "**Thanks for reading!** If you found this analysis helpful, please upvote.\n",
    "\n",
    "Questions or feedback? Let me know in the comments!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}